{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bde4775",
   "metadata": {},
   "source": [
    "WEB SCRAPING-ASSIGNMENT3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8637abeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Importing selenium webdriver\n",
    "from selenium import webdriver\n",
    "\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "# importing regex\n",
    "import re\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806b4096",
   "metadata": {},
   "source": [
    "1. Write a python program which searches all the product under a particular product from www.amazon.in. The \n",
    "product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for \n",
    "guitars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "326ef267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\lenovo\\anaconda\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Enter the product you want to search : guitar\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "\n",
    "import selenium                                  #library that is used to work with selenium\n",
    "\n",
    "from selenium import webdriver                   #importing webdriver module from selenium to open automated chrome window\n",
    "\n",
    "import pandas as pd                              #to create DataFrame\n",
    "\n",
    "from selenium.webdriver.common.by import By      #importing inbuilt class By \n",
    "\n",
    "import warnings                                  #to ignore any sort of warning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time                                      #use to stop search engine for few seconds\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"http://www.amazon.in/\")\n",
    "\n",
    "time.sleep(2)\n",
    "# Asking the user to input the keywords he/she wants to search\n",
    "user_inp = input('Enter the product you want to search : ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e0f4179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# searching the web element for user input\n",
    "search = driver.find_element(By.ID,\"twotabsearchtextbox\")\n",
    "search\n",
    "\n",
    "# sending the user input to search bar\n",
    "search.send_keys(user_inp)\n",
    "\n",
    "# locating the search button using xpath\n",
    "search_btn = driver.find_element(By.XPATH,\"//div[@class='nav-search-submit nav-sprite']/span/input\")\n",
    "\n",
    "# clicking on search button\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbae02c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e1245d3",
   "metadata": {},
   "source": [
    "2. In the above question, now scrape the following details of each product listed in first 3 pages of your search \n",
    "results and save it in a data frame and csv. In case if any product has less than 3 pages in search results then \n",
    "scrape all the products available under that product name. Details to be scraped are: \"Brand \n",
    "Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and \n",
    "“Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23600536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\lenovo\\anaconda\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Enter the product you want to search : guitar\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "\n",
    "import selenium                                  #library that is used to work with selenium\n",
    "\n",
    "from selenium import webdriver                   #importing webdriver module from selenium to open automated chrome window\n",
    "\n",
    "import pandas as pd                              #to create DataFrame\n",
    "\n",
    "from selenium.webdriver.common.by import By      #importing inbuilt class By \n",
    "\n",
    "import warnings                                  #to ignore any sort of warning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time                                      #use to stop search engine for few seconds\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"http://www.amazon.in/\")\n",
    "\n",
    "time.sleep(2)\n",
    "# Asking the user to input the keywords he/she wants to search\n",
    "user_inp = input('Enter the product you want to search : ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b64ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching URLs to open the pages\n",
    "urls = []          # empty list\n",
    "for i in range(0,3):      # for loop to scrape 3 pages\n",
    "    page_url = driver.find_elements(By.XPATH,\"//a[@class='a-link-normal a-text-normal']\")\n",
    "    for i in page_url:\n",
    "        urls.append(i.get_attribute(\"href\"))\n",
    "        next_btn = driver.find_element(By.XPATH,\"//li[@class='a-last']/a\")\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb5a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "855995c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_name = []\n",
    "product_name = []\n",
    "ratings = []\n",
    "num_ratings = []\n",
    "prices = []\n",
    "exchange = []\n",
    "exp_delivery = []\n",
    "availability = []\n",
    "other_details = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4ba08e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "    #fetching brand name \n",
    "    try:\n",
    "        brand = driver.find_element(By.XPATH,\"//a[@id='bylineInfo']\")\n",
    "        brand_name.append(brand.text)\n",
    "    except NoSuchElementException:\n",
    "        brand_name.append('-')\n",
    "    \n",
    "    \n",
    "    # fetching Name of the Product\n",
    "    try:\n",
    "        product = driver.find_element(By.XPATH,\"//span[@id='productTitle']\")\n",
    "        product_name.append(product.text)\n",
    "    except NoSuchElementException:\n",
    "        product_name.append('-')\n",
    "        \n",
    "        \n",
    "\n",
    "     #fetching ratings\n",
    "    try:\n",
    "        rating = driver.find_element(By.XPATH,\"//span[@class='a-size-base a-nowrap']/span\")\n",
    "        ratings.append(rating.text)\n",
    "    except NoSuchElementException:\n",
    "        ratings.append('-')\n",
    "        \n",
    " \n",
    "    #fetching  no of ratings\n",
    "    try:\n",
    "        num_rating = driver.find_element(By.XPATH,\"//span[@id='acrCustomerReviewText']\")\n",
    "        num_ratings.append(num_rating.text)\n",
    "    except NoSuchElementException:\n",
    "        num_ratings.append('-')\n",
    "        \n",
    "\n",
    "    #fetching price of the product\n",
    "    try:\n",
    "        price = driver.find_element(By.XPATH,\"//td[@class='a-span12']\")\n",
    "        prices.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        prices.append('-')\n",
    "        \n",
    "        \n",
    "    #fetching return/exchange\n",
    "    try:\n",
    "        exch = driver.find_element(By.XPATH,\"//span[@class='a-declarative']/div/a\")\n",
    "        exchange.append(exch.text)\n",
    "    except NoSuchElementException:\n",
    "        exchange.append('-')\n",
    "        \n",
    "\n",
    "    #fetching expected delivery\n",
    "    try:\n",
    "        delivery = driver.find_element(By.XPATH,\"//div[@class='a-section a-spacing-mini']/b\")\n",
    "        exp_delivery.append(delivery.text)\n",
    "    except NoSuchElementException:\n",
    "        exp_delivery.append('-')\n",
    "        \n",
    "\n",
    "    #fetching availability information\n",
    "    try:\n",
    "        avail = driver.find_element(By.XPATH,\"//span[@class='a-size-medium a-color-success']\")\n",
    "        availability.append(avail.text)\n",
    "    except NoSuchElementException:\n",
    "        availability.append('-')\n",
    "        \n",
    "    #other details\n",
    "    try:\n",
    "        oth_det = driver.find_element(By.XPATH,\"//ul[@class='a-unordered-list a-vertical a-spacing-mini']\")\n",
    "        other_details.append(oth_det.text)\n",
    "    except NoSuchElementException:\n",
    "        other_details.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b122fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(brand_name),len(product_name),len(ratings),len(num_ratings),len(prices),len(exchange),len(exp_delivery),len(availability),len(other_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a82f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "guitar = pd.DataFrame({})\n",
    "guitar['Brand Name'] = brand_name\n",
    "guitar['Name of the Product'] = product_name\n",
    "guitar['Rating'] = ratings\n",
    "guitar['No. of Ratings'] = num_ratings\n",
    "guitar['Price'] = prices\n",
    "guitar['Return/Exchange'] = exchange\n",
    "guitar['Expected Delivery'] = exp_delivery\n",
    "guitar['Availability'] = availability\n",
    "guitar['Other Details'] = other_details\n",
    "guitar['Product URL'] = urls\n",
    "guitar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0ae7307",
   "metadata": {},
   "outputs": [],
   "source": [
    "guitar.to_csv(\"Guitar.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1cc4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6decd537",
   "metadata": {},
   "source": [
    "3. Write a python program to access the search bar and search button on images.google.com and scrape 10 \n",
    "images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24100535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\lenovo\\anaconda\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "\n",
    "import selenium                                  #library that is used to work with selenium\n",
    "\n",
    "from selenium import webdriver                   #importing webdriver module from selenium to open automated chrome window\n",
    "\n",
    "import pandas as pd                              #to create DataFrame\n",
    "\n",
    "from selenium.webdriver.common.by import By      #importing inbuilt class By \n",
    "\n",
    "import warnings                                  #to ignore any sort of warning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time                                      #use to stop search engine for few seconds\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://images.google.com/\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "search=driver.find_element(By.XPATH,'//input[@class=\"gLFyf\"]')\n",
    "search.send_keys('Images')\n",
    "time.sleep(1)\n",
    "\n",
    "Click=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/button/div')\n",
    "Click.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf78e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword=['fruits','cars','Machine Learning','Guitar','Cakes']\n",
    "for key in keyword:\n",
    "    search=driver.find_element(By.XPATH,'//input[@class=\"og3lId\"]')\n",
    "    search.clear()\n",
    "    search.send_keys(str(key))\n",
    "    time.sleep(3)\n",
    "\n",
    "    Click=driver.find_element(By.XPATH,'//span[@class=\"n6h3Rc\"]')\n",
    "    Click.click()\n",
    "    time.sleep(3)\n",
    "\n",
    "    x=0\n",
    "    while x<10:\n",
    "        driver.execute_script(\"window.scrollBy(0,500)\")\n",
    "        time.sleep(1)\n",
    "        x=x+1\n",
    "\n",
    "    images=driver.find_elements(By.XPATH,'//img[@class=\"rg_i Q4LuWd\"]')\n",
    "    urls=[]\n",
    "    for i in images:\n",
    "        X=i.get_attribute('src')\n",
    "        if X is not None:\n",
    "            if(X[0:4]=='http'):\n",
    "                urls.append(X)\n",
    "    i=0\n",
    "    for i in range(len(urls)):\n",
    "        if i>10:\n",
    "            break\n",
    "        response=requests.get(urls[i])\n",
    "        file=open(r\"C:/Users/mehak/Downloads/images\"+str(i+m)+\".jpg\",\"wb\")\n",
    "        file.write(response.content)\n",
    "        m=m+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2ba85e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b890416",
   "metadata": {},
   "source": [
    "4. Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com\n",
    "and scrape following details for all the search results displayed on 1st page. Details to be scraped: “Brand \n",
    "Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”, \n",
    "“Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the \n",
    "details is missing then replace it by “- “. Save your results in a dataframe and CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bfaf4ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\lenovo\\anaconda\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "\n",
    "import selenium                                  #library that is used to work with selenium\n",
    "\n",
    "from selenium import webdriver                   #importing webdriver module from selenium to open automated chrome window\n",
    "\n",
    "import pandas as pd                              #to create DataFrame\n",
    "\n",
    "from selenium.webdriver.common.by import By      #importing inbuilt class By \n",
    "\n",
    "import warnings                                  #to ignore any sort of warning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time                                      #use to stop search engine for few seconds\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"http://www.flipkart.com/\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "login_page=driver.find_element(By.XPATH,'//button[@class=\"_2KpZ6l _2doB4z\"]')\n",
    "login_page.click()\n",
    "time.sleep(1)\n",
    "\n",
    "Product=driver.find_element(By.CLASS_NAME,'_3704LK')\n",
    "Product.send_keys(product)\n",
    "\n",
    "search_button=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "search_button.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d7be87",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=driver.find_elements(By.XPATH,'//a[@class=\"_1fQZEK\"]')\n",
    "urls=[]\n",
    "for i in url:\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "print(len(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b68366ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_namess=[]\n",
    "smartphone_names=[]\n",
    "colours=[]\n",
    "rams=[]\n",
    "storages=[]\n",
    "primarys=[]\n",
    "secondarys=[]\n",
    "displays=[]\n",
    "batterys=[]\n",
    "prices=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e5d775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    try:\n",
    "        driver.get(i)\n",
    "        clickonReadmore=driver.find_element(By.XPATH,'//button[@class=\"_2KpZ6l _1FH0tX\"]')\n",
    "        clickonReadmore.click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        try:\n",
    "            brand_names=driver.find_element(By.XPATH,'//span[@class=\"B_NuCI\"]')\n",
    "            brand_namess.append(brand_names.text)\n",
    "        except NoSuchElementException:\n",
    "            brand_namess.append('-')\n",
    "\n",
    "        try:\n",
    "            smartphone_name=driver.find_element(By.XPATH,'//div[@class=\"_3k-BhJ\"][1]/table/tbody/tr[3]/td[2]/ul/li')\n",
    "            smartphone_names.append(smartphone_name.text)\n",
    "        except NoSuchElementException:\n",
    "            smartphone_names.append('-')\n",
    "\n",
    "        try:\n",
    "            colour=driver.find_element(By.XPATH,'//div[@class=\"_3k-BhJ\"][1]/table/tbody/tr[4]/td[2]/ul/li')\n",
    "            colours.append(colour.text)\n",
    "        except NoSuchElementException:\n",
    "            colours.append('-')\n",
    "\n",
    "        try:\n",
    "            ram=driver.find_element(By.XPATH,'//div[@class=\"_3k-BhJ\"][4]/table/tbody/tr[2]/td[2]/ul/li')\n",
    "            rams.append(ram.text)\n",
    "        except NoSuchElementException:\n",
    "            rams.append('-')\n",
    "        try:\n",
    "            storage=driver.find_element(By.XPATH,'//div[@class=\"_3k-BhJ\"][4]/table/tbody/tr[1]/td[2]/ul/li')\n",
    "            storages.append(storage.text)\n",
    "        except NoSuchElementException:\n",
    "            storages.append('-')\n",
    "\n",
    "        try:\n",
    "            primary=driver.find_element(By.XPATH,'//div[@class=\"_3k-BhJ\"][5]/table/tbody/tr[2]/td[2]/ul/li')\n",
    "            primarys.append(primary.text)\n",
    "        except NoSuchElementException:\n",
    "            primarys.append('-')\n",
    "\n",
    "        try:\n",
    "            secondary=driver.find_element(By.XPATH,'//div[@class=\"_3k-BhJ\"][5]/table/tbody/tr[6]/td[2]/ul/li')\n",
    "            secondarys.append(secondary.text)\n",
    "        except NoSuchElementException:\n",
    "            secondarys.append('-')\n",
    "\n",
    "        try:\n",
    "            display=driver.find_element(By.XPATH,'//div[@class=\"_3k-BhJ\"][2]/table/tbody/tr[1]/td[2]/ul/li')\n",
    "            displays.append(display.text)\n",
    "        except NoSuchElementException:\n",
    "            displays.append('-')\n",
    "\n",
    "        try:\n",
    "            battery=driver.find_element(By.XPATH,'//div[@class=\"_2418kt\"]/ul/li[4]')\n",
    "            batterys.append(battery.text)\n",
    "        except NoSuchElementException:\n",
    "            batterys.append('-')\n",
    "        try:\n",
    "            price=driver.find_element(By.XPATH,'//div[@class=\"_30jeq3 _16Jk6d\"]')\n",
    "            prices.append(price.text)\n",
    "        except NoSuchElementException:\n",
    "            prices.append('-')\n",
    "\n",
    "\n",
    "    except TimeoutException:\n",
    "        brand_namess.append('-')\n",
    "        smartphone_names.append('-')\n",
    "        colours.append('-')\n",
    "        rams.append('-')\n",
    "        storages.append('-')\n",
    "        primarys.append('-')\n",
    "        secondarys.append('-')\n",
    "        displays.append('-')\n",
    "        batterys.append('-')\n",
    "        prices.append('-')\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612c0044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df=pd.DataFrame({\n",
    "    'brand_names':brand_namess,\n",
    "    'smartphone_name':smartphone_names,\n",
    "    'colour':colours,\n",
    "    'ram':rams,\n",
    "    'storage':storages,\n",
    "    'primary':primarys,\n",
    "    'secondary':secondarys,\n",
    "    'display':displays,\n",
    "    'battery':batterys,\n",
    "    'price':prices})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cc8c49ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"smartphones.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6dc386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ca278fd",
   "metadata": {},
   "source": [
    "5. Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "49882420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\lenovo\\anaconda\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "\n",
    "import selenium                                  #library that is used to work with selenium\n",
    "\n",
    "from selenium import webdriver                   #importing webdriver module from selenium to open automated chrome window\n",
    "\n",
    "import pandas as pd                              #to create DataFrame\n",
    "\n",
    "from selenium.webdriver.common.by import By      #importing inbuilt class By \n",
    "\n",
    "import warnings                                  #to ignore any sort of warning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time                                      #use to stop search engine for few seconds\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "url = \"https://www.google.co.in/maps\"\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a4e891c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter City name that has to be searched : Delhi\n",
      "URL Extracted:  https://www.google.co.in/maps/place/Delhi+-+Jaipur+Expy/@18.8181772,76.7698374,7z/data=!4m6!3m5!1s0x396db271003d2389:0xf4b5bfd7620ef35f!8m2!3d27.8279534!4d76.2598046!16s%2Fg%2F11f123sjxk?entry=ttu\n",
      "Latitude = 18.8181772, Longitude = 76.7698374\n"
     ]
    }
   ],
   "source": [
    "City = input('Enter City name that has to be searched : ')\n",
    "search_bar = driver.find_element(By.ID,'searchboxinput')\n",
    "search_bar.click()\n",
    "time.sleep(2)\n",
    "\n",
    "#sending keys to find cities\n",
    "search_bar.send_keys(City)\n",
    "\n",
    "#checking for webelement and clicking on search button\n",
    "search_btn = driver.find_element(By.ID,\"searchbox-searchbutton\")\n",
    "search_btn.click()\n",
    "time.sleep(2)\n",
    "\n",
    "try:\n",
    "    url_str = driver.current_url\n",
    "    print(\"URL Extracted: \", url_str)\n",
    "    latitude_longitude = re.findall(r'@(.*)data',url_str)\n",
    "    if len(latitude_longitude):\n",
    "        lat_lng_list = latitude_longitude[0].split(\",\")\n",
    "        if len(lat_lng_list)>=2:\n",
    "            latitude = lat_lng_list[0]\n",
    "            longitude = lat_lng_list[1]\n",
    "        print(\"Latitude = {}, Longitude = {}\".format(latitude, longitude))\n",
    "except Exception as e:\n",
    "        print(\"Error: \", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f61cc44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7990905",
   "metadata": {},
   "source": [
    "6. Write a program to scrap all the available details of best gaming laptops from digit.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ca67bc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\lenovo\\anaconda\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "\n",
    "import selenium                                  #library that is used to work with selenium\n",
    "\n",
    "from selenium import webdriver                   #importing webdriver module from selenium to open automated chrome window\n",
    "\n",
    "import pandas as pd                              #to create DataFrame\n",
    "\n",
    "from selenium.webdriver.common.by import By      #importing inbuilt class By \n",
    "\n",
    "import warnings                                  #to ignore any sort of warning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time                                      #use to stop search engine for few seconds\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://digit.in/\")\n",
    "driver.maximize_window()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4003c84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,\"//div[@class='listing_container']//ul//li[9]\").click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41843523",
   "metadata": {},
   "outputs": [],
   "source": [
    "Laptop_Name = []\n",
    "Operating_sys = []\n",
    "Display = []\n",
    "Processor = []\n",
    "Memory = []\n",
    "Weight = []\n",
    "Dimensions = []\n",
    "Graph_proc = []\n",
    "Price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "141e7bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the data of laptop names\n",
    "laptop_name= driver.find_elements(By.XPATH,'//div[@class=\"left_side\"]/a/h3')\n",
    "for name in laptop_name:\n",
    "    Laptop_Name.append(name.text)\n",
    "\n",
    "\n",
    "#Scraping the data of operating system\n",
    "try:\n",
    "    op_sys = driver.find_elements(By.XPATH,\"//div[@class='product-detail']/div/ul/li[1]/div/div\")\n",
    "    for os in op_sys:\n",
    "        Operating_sys.append(os.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "#Scraping data of display of the laptop\n",
    "try:\n",
    "    display= driver.find_elements(By.XPATH,\"//div[@class='product-detail']/div/ul/li[2]/div/div\")\n",
    "    for disp in display:\n",
    "        Display.append(disp.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "\n",
    "#Scraping data of Processor\n",
    "try:\n",
    "    processor = driver.find_elements(By.XPATH,\"//div[@class='Spcs-details'][1]/table/tbody/tr[5]/td[3]\")\n",
    "    for pro in processor:\n",
    "        Processor.append(pro.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "#Scraping data of memory\n",
    "try:\n",
    "    memory = driver.find_elements(By.XPATH,\"//div[@class='Spcs-details'][1]/table/tbody/tr[6]/td[3]\")\n",
    "    for memo in memory:\n",
    "        Memory.append(memo.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "#Scraping data of dimensions\n",
    "try:\n",
    "    dimension = driver.find_elements(By.XPATH,\"//div[@class='Spcs-details'][1]/table/tbody/tr[7]/td[3]\")\n",
    "    for dim in dimension:\n",
    "        Dimensions.append(dim.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "\n",
    "#Scraping data of Graph processor\n",
    "try:\n",
    "    graph = driver.find_elements(By.XPATH,\"//div[@class='Spcs-details'][1]/table/tbody/tr[7]/td[3]\")\n",
    "    for gra in graph:\n",
    "        Graph_proc.append(gra.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "\n",
    "#Scraping data of price\n",
    "try:\n",
    "    price = driver.find_elements(By.XPATH,\"//td[@class='smprice']\")\n",
    "    for pri in price:\n",
    "        Price.append(pri.text.replace('₹','Rs '))\n",
    "except NoSuchElementException:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d62c5c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7 7 7 7 7 7 7\n"
     ]
    }
   ],
   "source": [
    "print(len(Laptop_Name),len(Operating_sys),len(Display),len(Processor),len(Memory),len(Dimensions),len(Graph_proc),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a22fb850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop Name</th>\n",
       "      <th>Operating system</th>\n",
       "      <th>Display</th>\n",
       "      <th>Processor</th>\n",
       "      <th>Memory</th>\n",
       "      <th>Dimensions</th>\n",
       "      <th>Graphical Processor</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows 11 Home</td>\n",
       "      <td>17.3\" (2560 x 1440)</td>\n",
       "      <td>16 GB DDR5GB RAM &amp; 1 TB SSD</td>\n",
       "      <td>12 GB DDR6 NVIDIA GeForce RTX 4080 Graphics card</td>\n",
       "      <td>397.1 x 262 x 27 mm dimension &amp; 2.78 kg weight</td>\n",
       "      <td>397.1 x 262 x 27 mm dimension &amp; 2.78 kg weight</td>\n",
       "      <td>Rs  269,777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows 11 Home</td>\n",
       "      <td>17.3\" (3840 x 2160)</td>\n",
       "      <td>64 GB DDR5GB RAM &amp; 2 TB SSD</td>\n",
       "      <td>16 GB DDR6 NVIDIA GeForce RTX 3080Ti Graphics ...</td>\n",
       "      <td>397 x 330 x 23 mm dimension &amp; 3.3 kg weight</td>\n",
       "      <td>397 x 330 x 23 mm dimension &amp; 3.3 kg weight</td>\n",
       "      <td>Rs  499,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows 11 Home</td>\n",
       "      <td>16\" (2560 x 1600)</td>\n",
       "      <td>32 GB DDR5GB RAM &amp; 1 TB SSD</td>\n",
       "      <td>NVIDIA GeForce RTX 3070 Ti Graphics card</td>\n",
       "      <td>359.9 x 264.4 x 19.9 mm dimension &amp; 3.6 kg weight</td>\n",
       "      <td>359.9 x 264.4 x 19.9 mm dimension &amp; 3.6 kg weight</td>\n",
       "      <td>Rs  179,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows 11 Home</td>\n",
       "      <td>18\" (1920 x 1200)</td>\n",
       "      <td>32 GB DDR5GB RAM &amp; 1 TB SSD</td>\n",
       "      <td>12 GB DDR6 NVIDIA GeForce RTX 4080 Graphics card</td>\n",
       "      <td>294 x 399 x 23 mm dimension &amp; 3.1 kg weight</td>\n",
       "      <td>294 x 399 x 23 mm dimension &amp; 3.1 kg weight</td>\n",
       "      <td>Rs  279,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows 11 Home</td>\n",
       "      <td>16\" (2560 x 1600)</td>\n",
       "      <td>16 GB DDR5GB RAM &amp; 1 TB SSD</td>\n",
       "      <td>8 GB DDR6 NVIDIA GeForce RTX 4060 Graphics card</td>\n",
       "      <td>360 x 279 x 28 mm dimension &amp; 2.6 kg weight</td>\n",
       "      <td>360 x 279 x 28 mm dimension &amp; 2.6 kg weight</td>\n",
       "      <td>Rs  149,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows 11 Home</td>\n",
       "      <td>14\" (1920 x 1200)</td>\n",
       "      <td>16 GB DDR5GB RAM &amp; 1 TB SSD</td>\n",
       "      <td>8 GB DDR6 AMD Radeon RX 6700S Graphics card</td>\n",
       "      <td>312 x 227 x 19 mm dimension &amp; 1.65 kg weight</td>\n",
       "      <td>312 x 227 x 19 mm dimension &amp; 1.65 kg weight</td>\n",
       "      <td>Rs  156,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows 11 Home</td>\n",
       "      <td>15.6\" (1920 x 1080)</td>\n",
       "      <td>16 GB DDR5GB RAM &amp; 1 TB SSD</td>\n",
       "      <td>8 GB DDR6 NVIDIA GeForce RTX 4060 Graphics card</td>\n",
       "      <td>&amp; 1.98 kg weight</td>\n",
       "      <td>&amp; 1.98 kg weight</td>\n",
       "      <td>Rs  125,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Laptop Name Operating system              Display  \\\n",
       "0          NaN  Windows 11 Home  17.3\" (2560 x 1440)   \n",
       "1          NaN  Windows 11 Home  17.3\" (3840 x 2160)   \n",
       "2          NaN  Windows 11 Home    16\" (2560 x 1600)   \n",
       "3          NaN  Windows 11 Home    18\" (1920 x 1200)   \n",
       "4          NaN  Windows 11 Home    16\" (2560 x 1600)   \n",
       "5          NaN  Windows 11 Home    14\" (1920 x 1200)   \n",
       "6          NaN  Windows 11 Home  15.6\" (1920 x 1080)   \n",
       "\n",
       "                     Processor  \\\n",
       "0  16 GB DDR5GB RAM & 1 TB SSD   \n",
       "1  64 GB DDR5GB RAM & 2 TB SSD   \n",
       "2  32 GB DDR5GB RAM & 1 TB SSD   \n",
       "3  32 GB DDR5GB RAM & 1 TB SSD   \n",
       "4  16 GB DDR5GB RAM & 1 TB SSD   \n",
       "5  16 GB DDR5GB RAM & 1 TB SSD   \n",
       "6  16 GB DDR5GB RAM & 1 TB SSD   \n",
       "\n",
       "                                              Memory  \\\n",
       "0   12 GB DDR6 NVIDIA GeForce RTX 4080 Graphics card   \n",
       "1  16 GB DDR6 NVIDIA GeForce RTX 3080Ti Graphics ...   \n",
       "2           NVIDIA GeForce RTX 3070 Ti Graphics card   \n",
       "3   12 GB DDR6 NVIDIA GeForce RTX 4080 Graphics card   \n",
       "4    8 GB DDR6 NVIDIA GeForce RTX 4060 Graphics card   \n",
       "5        8 GB DDR6 AMD Radeon RX 6700S Graphics card   \n",
       "6    8 GB DDR6 NVIDIA GeForce RTX 4060 Graphics card   \n",
       "\n",
       "                                          Dimensions  \\\n",
       "0     397.1 x 262 x 27 mm dimension & 2.78 kg weight   \n",
       "1        397 x 330 x 23 mm dimension & 3.3 kg weight   \n",
       "2  359.9 x 264.4 x 19.9 mm dimension & 3.6 kg weight   \n",
       "3        294 x 399 x 23 mm dimension & 3.1 kg weight   \n",
       "4        360 x 279 x 28 mm dimension & 2.6 kg weight   \n",
       "5       312 x 227 x 19 mm dimension & 1.65 kg weight   \n",
       "6                                   & 1.98 kg weight   \n",
       "\n",
       "                                 Graphical Processor        Price  \n",
       "0     397.1 x 262 x 27 mm dimension & 2.78 kg weight  Rs  269,777  \n",
       "1        397 x 330 x 23 mm dimension & 3.3 kg weight  Rs  499,990  \n",
       "2  359.9 x 264.4 x 19.9 mm dimension & 3.6 kg weight  Rs  179,990  \n",
       "3        294 x 399 x 23 mm dimension & 3.1 kg weight  Rs  279,990  \n",
       "4        360 x 279 x 28 mm dimension & 2.6 kg weight  Rs  149,990  \n",
       "5       312 x 227 x 19 mm dimension & 1.65 kg weight  Rs  156,990  \n",
       "6                                   & 1.98 kg weight  Rs  125,000  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Gaming_Laptop=pd.DataFrame({})\n",
    "Gaming_Laptop['Laptop Name'] = Laptop_Name\n",
    "Gaming_Laptop['Operating system'] = Operating_sys\n",
    "Gaming_Laptop['Display'] = Display\n",
    "Gaming_Laptop['Processor'] = Processor\n",
    "Gaming_Laptop['Memory'] = Memory\n",
    "Gaming_Laptop['Dimensions'] = Dimensions\n",
    "Gaming_Laptop['Graphical Processor'] = Graph_proc\n",
    "Gaming_Laptop['Price'] = Price\n",
    "Gaming_Laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9596510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c7ff97e",
   "metadata": {},
   "source": [
    "7. Write a python program to scrape the details for all billionaires from www.forbes.com. Details to be scrapped: \n",
    "“Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, “Industry”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "15a36bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\lenovo\\anaconda\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "\n",
    "import selenium                                  #library that is used to work with selenium\n",
    "\n",
    "from selenium import webdriver                   #importing webdriver module from selenium to open automated chrome window\n",
    "\n",
    "import pandas as pd                              #to create DataFrame\n",
    "\n",
    "from selenium.webdriver.common.by import By      #importing inbuilt class By \n",
    "\n",
    "import warnings                                  #to ignore any sort of warning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time                                      #use to stop search engine for few seconds\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"http://www.forbes.com/\")\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "\n",
    "lists = driver.find_element(By.XPATH,'/html/body/div[1]/header/nav/div[1]/div/div/div[1]')\n",
    "lists.click()\n",
    "\n",
    "billionaires = driver.find_element(By.XPATH,'/html/body/div[1]/header/nav/div[1]/div/div/div[2]/ul/li[1]/div[1]/span')\n",
    "billionaires.click()\n",
    "\n",
    "world_billionaires = driver.find_element(By.XPATH,'/html/body/div[1]/header/nav/div[1]/div/div/div[2]/ul/li[1]/div[2]/div[3]/ul/li[1]/a')\n",
    "world_billionaires.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3a9309b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=[]\n",
    "name=[]\n",
    "net_worth=[]\n",
    "age=[]\n",
    "citizenship=[]\n",
    "source=[]\n",
    "industry=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2dfa86d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,200):\n",
    "    try:\n",
    "        ranks = driver.find_elements(By.XPATH,'//div[@class=\"rank\"]')\n",
    "        for i in ranks:\n",
    "            rank.append(i.text)\n",
    "\n",
    "        names=driver.find_elements(By.XPATH,'//div[@class=\"personName\"]/div')\n",
    "        for i in names:\n",
    "            name.append(i.text)\n",
    "\n",
    "        net_worths=driver.find_elements(By.XPATH,'//div[@class=\"netWorth\"]/div[1]')\n",
    "        for i in net_worths:\n",
    "            net_worth.append(i.text)\n",
    "\n",
    "        ages=driver.find_elements(By.XPATH,'//div[@class=\"age\"]/div')\n",
    "        for i in ages:\n",
    "            age.append(i.text)\n",
    "\n",
    "        citizenships=driver.find_elements(By.XPATH,'//div[@class=\"countryOfCitizenship\"]')\n",
    "        for i in citizenships:\n",
    "            citizenship.append(i.text)\n",
    "\n",
    "        sources=driver.find_elements(By.XPATH,'//div[@class=\"source\"]')\n",
    "        for i in sources:\n",
    "            source.append(i.text)\n",
    "\n",
    "        industrys=driver.find_elements(By.XPATH,'//div[@class=\"category\"]//div')\n",
    "        for i in industrys:\n",
    "            industry.append(i.text)\n",
    "\n",
    "\n",
    "        clicknxt=driver.find_element(By.XPATH,'//button[@class=\"pagination-btn pagination-btn--next \"]')\n",
    "        clicknxt.click()\n",
    "        time.sleep(1)\n",
    "    except NoSuchElementException:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cce16c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({\n",
    "    'Rank':rank,\n",
    "    'Name':name,\n",
    "    'Net_worth':net_worth,\n",
    "    'Age':age,\n",
    "    'Citizenship':citizenship,\n",
    "    'Source':source,\n",
    "    'Industry':industry})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42eff01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd3bd9dd",
   "metadata": {},
   "source": [
    "8. Write a program to extract at least 500 Comments, Comment upvote and time when comment was posted \n",
    "from any YouTube Video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ac7a9945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\lenovo\\anaconda\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "\n",
    "import selenium                                  #library that is used to work with selenium\n",
    "\n",
    "from selenium import webdriver                   #importing webdriver module from selenium to open automated chrome window\n",
    "\n",
    "import pandas as pd                              #to create DataFrame\n",
    "\n",
    "from selenium.webdriver.common.by import By      #importing inbuilt class By \n",
    "\n",
    "import warnings                                  #to ignore any sort of warning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time                                      #use to stop search engine for few seconds\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://www.youtube.com/watch?v=BBAyRBTfsOU\")\n",
    "driver.maximize_window()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "12b386b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scroll is completed\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while(i<150):\n",
    "    driver.execute_script(\"window.scrollBy(0,500)\")\n",
    "    i+=1\n",
    "    time.sleep(1.2)\n",
    "print('Scroll is completed')\n",
    "\n",
    "#Fetch like,cmnt and time\n",
    "try:\n",
    "    time=driver.find_elements(By.XPATH,'//yt-formatted-string[@class=\"published-time-text style-scope ytd-comment-renderer\"]/a')\n",
    "    times=[]\n",
    "    for i in time[0:500]:\n",
    "        times.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    times.append('-')\n",
    "\n",
    "try:\n",
    "    cmnt=driver.find_elements(By.XPATH,'//yt-formatted-string[@id=\"content-text\"]')\n",
    "    cmnts=[]\n",
    "    for i in cmnt[0:500]:\n",
    "        cmnts.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    cmnts.append('-')\n",
    "\n",
    "try:\n",
    "    up=driver.find_elements(By.XPATH,'//span[@id=\"vote-count-middle\"]')\n",
    "    ups=[]\n",
    "    for i in up[0:500]:\n",
    "        ups.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    ups.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf00bc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({\n",
    "    'Comments':cmnts,\n",
    "    'Comment_Upvote':ups,\n",
    "    'Time':times})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1056f5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2721dee8",
   "metadata": {},
   "source": [
    "9. Write a python program to scrape a data for all available Hostels from https://www.hostelworld.com/ in \n",
    "“London” location. You have to scrape hostel name, distance from city centre, ratings, total reviews, overall \n",
    "reviews, privates from price, dorms from price, facilities and property description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8a7826e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\lenovo\\anaconda\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\lenovo\\anaconda\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "\n",
    "import selenium                                  #library that is used to work with selenium\n",
    "\n",
    "from selenium import webdriver                   #importing webdriver module from selenium to open automated chrome window\n",
    "\n",
    "import pandas as pd                              #to create DataFrame\n",
    "\n",
    "from selenium.webdriver.common.by import By      #importing inbuilt class By \n",
    "\n",
    "import warnings                                  #to ignore any sort of warning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time                                      #use to stop search engine for few seconds\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"http://www.hostelworld.com/\")\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "\n",
    "loc = driver.find_element(By.XPATH,'/html/body/div[3]/div/div/div[2]/div[2]/div/div/div[4]/div/div[2]/div/div[1]/div/div/div/input')\n",
    "loc.send_keys(\"London\")\n",
    "\n",
    "driver.find_element(By.XPATH,'/html/body/div[3]/div/div/div[2]/div[2]/div/div/div[4]/div/div[2]/div/div[1]/div/div/ul/li[2]/div').click()\n",
    "\n",
    "driver.find_element(By.XPATH,'/html/body/div[3]/div/div/div[2]/div[2]/div/div/div[4]/div/div[2]/div/div[5]/button').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "589fe703",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = []\n",
    "Distance = []\n",
    "Rating = []\n",
    "Reviews = []\n",
    "Overall = []\n",
    "Privates = []\n",
    "Dorms = []\n",
    "Facilities = []\n",
    "Property = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ee15ed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Names\n",
    "N = driver.find_elements(By.XPATH,'//h2[@class=\"title title-6\"]')\n",
    "for i in N:\n",
    "    Name.append(i.text)\n",
    "\n",
    "#Scrapping distance from city centre\n",
    "try:\n",
    "    D = driver.find_elements(By.XPATH,'//span[@class=\"description\"]')\n",
    "    for i in D:\n",
    "        Distance.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Distance.append(\"-\")\n",
    "\n",
    "#Scrapping ratings\n",
    "try:\n",
    "    RT = driver.find_elements(By.XPATH,'//div[@class=\"rating rating-summary-container big\"]')\n",
    "    for i in RT:\n",
    "        Rating.append(i.text[:][0:3])\n",
    "except NoSuchElementException:\n",
    "    Rating.append(\"-\")\n",
    "\n",
    "    #Scrapping total reviews\n",
    "try:\n",
    "    RV = driver.find_elements(By.XPATH,'//div[@class=\"reviews\"]')\n",
    "    for i in RV:\n",
    "        Reviews.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Reviews.append(\"-\")\n",
    "\n",
    "#Scrapping overall reviews\n",
    "try:\n",
    "    O = driver.find_elements(By.XPATH,'//div[@class=\"keyword\"]')\n",
    "    for i in O:\n",
    "        Overall.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Overall.append(\"-\")\n",
    "\n",
    "#Scrapping privates from price\n",
    "P = driver.find_elements(By.XPATH,'//div[@class=\"price-col\"]')[0::2]\n",
    "for i in P:\n",
    "    Privates.append(i.text.replace('\\n',': ').replace('No Privates Available','NaN'))\n",
    "\n",
    "#Scrapping Dorms from price\n",
    "P = driver.find_elements(By.XPATH,'//div[@class=\"price-col\"]')[1::2]\n",
    "for i in P:\n",
    "    Dorms.append(i.text.replace('\\n',': ').replace('No Dorms Available','NaN'))\n",
    "\n",
    "#Scrapping Facilities\n",
    "try:\n",
    "    F = driver.find_elements(By.XPATH,'//div[@class=\"facilities-label facilities\"]')\n",
    "    for i in F:\n",
    "        Facilities.append(i.text.replace('\\n',', '))\n",
    "except NoSuchElementException:\n",
    "    Facilities.append(\"-\")\n",
    "\n",
    "    #Scrapping property description.\n",
    "try:\n",
    "    PD = driver.find_elements(By.XPATH,'//div[@class=\"rating-factors prop-card-tablet rating-factors small\"]')\n",
    "    for i in PD:\n",
    "        Property.append(i.text.replace('\\n',', '))\n",
    "except NoSuchElementException:\n",
    "    Property.append(\"-\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90498127",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Name),len(Distance),len(Rating),len(Reviews),len(Privates),len(Dorms),len(Facilities),len(Property))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a856725",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Hostel name':Name,\n",
    "                   'Distance from city centre':Distance,\n",
    "                   'Rating':Rating,\n",
    "                   'Total reviews':Reviews,\n",
    "                   'Privates from price':Privates,\n",
    "                   'Dorms from price':Dorms,\n",
    "                   'Facilities':Facilities,\n",
    "                   'Property description':Property})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05592df4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
